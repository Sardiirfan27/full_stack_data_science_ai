# ==========================
# Airflow PostgreSQL Configuration
# ==========================
AIRFLOW_POSTGRES_USER=ml_user
AIRFLOW_POSTGRES_PASSWORD=ml_pass
AIRFLOW_POSTGRES_DB=ml_project
AIRFLOW_POSTGRES_PORT=5432
AIRFLOW_POSTGRES_HOST=postgres_airflow

# ==========================
# Airflow Configuration
# ==========================
AIRFLOW_UID=5000
AIRFLOW_GID=0
AIRFLOW__CORE__EXECUTOR=CeleryExecutor   # CeleryExecutor untuk worker terdistribusi
AIRFLOW__CORE__FERNET_KEY=UKMzEm3yIuFYEq1y3-2FxPNWSVwRASpahmQ9kQfEr8E=  # Generate via: python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
AIRFLOW__CORE__DAGS_FOLDER=/opt/airflow/dags
AIRFLOW__CORE__LOAD_EXAMPLES=False
AIRFLOW__CORE__DEFAULT_TIMEZONE=Asia/Jakarta

# AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://ml_user:ml_pass@postgres:5432/ml_project
#postgresql://<USER>:<PASSWORD>@<HOST>:<PORT>/<DATABASE>
AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://ml_user:ml_pass@postgres_airflow:5432/ml_project
AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://ml_user:ml_pass@postgres_airflow:5432/ml_project
AIRFLOW__CELERY__BROKER_URL=redis://redis:6379/0
AIRFLOW__WEBSERVER__SECRET_KEY=A2bJ9rLDuZGuQ7Cbfy0X5N9Wkgk4BLw6hVNsnYZKcD0=

# SMTP Configuration
AIRFLOW__SMTP__SMTP_HOST=smtp.gmail.com
AIRFLOW__SMTP__SMTP_STARTTLS=True
AIRFLOW__SMTP__SMTP_SSL=False
AIRFLOW__SMTP__SMTP_PORT=587
AIRFLOW__SMTP__SMTP_MAIL_FROM=sardiirfan27@gmail.com
AIRFLOW__SMTP__SMTP_USER=sardiirfan27@gmail.com
AIRFLOW__SMTP__SMTP_PASSWORD="your_email_password_here"

# ==========================
# Airflow init
# ==========================

_AIRFLOW_DB_UPGRADE=True
_AIRFLOW_WWW_USER_CREATE=True
_AIRFLOW_WWW_USER_USERNAME=airflow
_AIRFLOW_WWW_USER_PASSWORD=airflow

# ==========================
# Google Cloud / BigQuery
# ==========================
GCP_PROJECT_ID=axial-entropy-351511
BIGQUERY_DATASET=telco_customers_churn
BIGQUERY_TABLE=customers_summary

# Key Path inside container: /opt/project/gcp_service_key.json
GCP_CREDENTIALS=/opt/project/gcp_service_key.json  #"D:/ml_project/telco customer churn/gcp_service_key.json"


# Model Path
MODEL_PATH=/opt/project/models/
#python path
# Add both the project root and the ml/ folder to the Python module search path
# This allows imports like `from data_loader import load_data` and `from ml.train import train_model` to work correctly inside Airflow
PYTHONPATH=/opt/project:/opt/project/ml


# MLflow PostgreSQL credentials
MLFLOW_POSTGRES_USER=mlflow_user
MLFLOW_POSTGRES_PASSWORD=mlflow_pass
MLFLOW_POSTGRES_DB=mlflow_db
MLFLOW_POSTGRES_PORT=5432

# MLflow
MLFLOW_TRACKING_URI=http://mlflow:5000 #mlflow is the hostname of the MLflow service in Compose.
MLFLOW_ARTIFACT=file:///opt/project/mlflow_runs
MLFLOW_BACKEND=postgresql://mlflow_user:mlflow_pass@postgres_mlflow:5432/mlflow_db #postgresql://<USER>:<PASSWORD>@<HOST>:<PORT>/<DATABASE>
MLFLOW_EXPERIMENT_NAME=mlflow_telco_customers_churn
MLFLOW_PORT=5000
MLFLOW_HOST=0.0.0.0

# redis
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_DB=0
REDIS_DB=0
REDIS_TTL=60  # cache time in seconds
RATE_LIMIT=5
RATE_PERIOD=10

# fastapi
api_key=your_fastapi_api_key_here




